# RL-Stock-Trader
This Python code implements a stock trading agent using reinforcement learning with a deep Q-network (DQN). The code uses the gym environment for simulating the stock trading process and yfinance to fetch historical stock data (for Apple in this case). The environment (StockTradingEnv) allows the agent to take actions such as buying, selling, or holding stock, and rewards the agent based on its profit and penalties for holding stocks too long or incurring losses. The deep Q-network is built using TensorFlow's Keras API, with the network consisting of fully connected layers that learn the optimal actions to maximize profit. The agent is trained by interacting with the environment, storing past experiences in memory (deque), and learning from them through mini-batch training. During training, the agent starts by exploring actions randomly and gradually shifts to exploiting learned strategies using a decaying epsilon-greedy policy. The agent's performance in terms of total profit and rewards is visualized in real time using Matplotlib. Additionally, the model is saved to a file (stock_trading_agent.keras) after every 100 episodes, and the total number of episodes run is stored in a text file for future use.
